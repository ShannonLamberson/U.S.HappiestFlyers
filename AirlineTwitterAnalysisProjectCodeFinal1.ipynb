{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was used to collect airline tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer, TwythonError, TwythonRateLimitError, TwythonAuthError\n",
    "from unidecode import unidecode\n",
    "import sys\n",
    "import json\n",
    "from time import sleep\n",
    "import time\n",
    "\n",
    "\n",
    "tweets = []\n",
    "\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    '''our own subclass of TwythonStremer'''\n",
    "\n",
    "    # overriding\n",
    "    def on_success(self, data):\n",
    "        try:\n",
    "            if data['lang'] == 'en':\n",
    "                test = data['text']\n",
    "                if not test.startswith('RT'):\n",
    "                    tweets.append(unidecode(data['text']))\n",
    "                    print 'received tweet #', len(tweets), unidecode(data['text'])[:100]\n",
    "                \n",
    "        except:\n",
    "            print 'Error encountered'\n",
    "        \n",
    "#==============================================================================\n",
    "        if len(tweets) % 10 == 0:\n",
    "            self.store_json()\n",
    "            #sleep(30)\n",
    "            #self.disconnect()\n",
    "\n",
    "#==============================================================================\n",
    "        \n",
    "#==============================================================================\n",
    "        if len(tweets) >= 10000:\n",
    "              self.store_json()\n",
    "              self.disconnect()\n",
    "              return False\n",
    "#==============================================================================\n",
    "    # overriding\n",
    "    def on_error(self, status_code, data):\n",
    "        print status_code, data\n",
    "        #self.disconnect()\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "    def store_json(self):\n",
    "        t=time.localtime()\n",
    "        timestamp = time.strftime('%b_%d_%Y',t)\n",
    "        #with open('tweet_stream_{}_{}.json'.format('Airlines', timestamp), 'w') as f:\n",
    "        with open('tweet_stream_airlines_{}.json'.format(timestamp), 'w') as f:    \n",
    "            json.dump(tweets, f, indent=4)\n",
    "  \n",
    "#==============================================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    CONSUMER_KEY = 'Input_Consumer_Key",
    "    CONSUMER_SECRET = 'Input_Consumer_Secret",
    "    ACCESS_TOKEN = 'Input_Access_Token",
    "    ACCESS_TOKEN_SECRET = 'Input_Access_Token_Secret",
    "\n",
    "    stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "#==============================================================================\n",
    "    if len(sys.argv) > 1:\n",
    "        keyword = sys.argv[1]\n",
    "    else:\n",
    "        keyword = '@AlaskaAir, @AmericanAir, @DeltaAssist, @FlyFrontier, @Jetblue, @SouthwestAir, @United, @VirginAmerica'\n",
    "        #keyword = 'Chicago'\n",
    "#==============================================================================\n",
    "\n",
    "        \n",
    "#    stream.statuses.filter(track=keyword)\n",
    "#import sys #Do this if you want to log error output\n",
    "    timeout = time.time() + 60 * 1 #minutes from now\n",
    "    test = -1\n",
    "    while True:  #Endless loop: personalize to suit your own purposes\n",
    "        \n",
    "        if test == 0 or time.time() > timeout:\n",
    "            stream.store_json()\n",
    "            break\n",
    "        \n",
    "        test = test - 1\n",
    "        \n",
    "        try: \n",
    "            stream.statuses.filter(track=keyword)\n",
    "            #stream.statuses.filter(locations=\"-87.51,41.46,-87.33,42.02\")\n",
    "        except:\n",
    "            e = sys.exc_info()[0]  #Get exception info (optional)\n",
    "            print 'ERROR:',e  #Print exception info (optional)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below filter the tweets\n",
    "- get rid of punctuation and non essential Tweets like ones about the Cuba flight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import re\n",
    "\n",
    "# open a text file\n",
    "json_data = open('tweet_stream_Airlines_Dec_04_20165k.json').read()\n",
    "data = json.loads(json_data)\n",
    "\n",
    "######## pull out the extra characters\n",
    "###### take out characters\n",
    "#####string out the cuba tweets\n",
    "\n",
    "comment = []\n",
    "for line in data:\n",
    "    if \"Cuba\" in line:\n",
    "        continue\n",
    "    if \"@djsnake\" in line:\n",
    "        continue\n",
    "    if \"havana\" in line:\n",
    "        continue\n",
    "    else:\n",
    "        ln=line.lstrip()\n",
    "        ln=line.rstrip()\n",
    "        ln=re.sub(\"[^_a-zA-Z0-9]\", ' ', line)\n",
    "        comment.append(ln)\n",
    "print(comment)\n",
    "\n",
    "\n",
    "#######creating new file      \n",
    "keyword=\"airline\"\n",
    "t=time.localtime()\n",
    "timestamp = time.strftime('%b_%d_%Y',t)\n",
    "        #with open('tweet_stream_{}_{}.json'.format('Airlines', timestamp), 'w') as f:\n",
    "with open('airlineTweetPull_{}_{}.json'.format(keyword, timestamp), 'w') as f:    \n",
    "    json.dump(comment, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive model - trained to predict the sentiment of Tweets (positive, negative and neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "########create tweets to train on\n",
    "pos_tweets = [('I love this car', 'positive'),\n",
    "('This view is amazing', 'positive'),\n",
    "('I feel great this morning', 'positive'),\n",
    "('I am so excited and happy about the concert', 'positive'),\n",
    "('He is my awesome best friend', 'positive'),\n",
    "('just had the smoothest landing I\\'ve ever felt. And I\\'ve flown a lot. Super impressed with @AmericanAir ', 'positive'),\n",
    "('This is a shout out to @Uber, @united &amp; @Enterprise, who have all been amazing this morning.','positive'),\n",
    "('now airborne. Weather permitting','positive'),\n",
    "('Shoutout','positive'),\n",
    "('I m loving this  so freaking awesome    great job','positive'),\n",
    "('I will say this  your military friendly kiosks made it a little easier to check in','positive')\n",
    "]\n",
    "\n",
    "\n",
    "neg_tweets = [('I do not like this car', 'negative'),\n",
    "('This view is horrible', 'negative'),\n",
    "('I feel tired this morning', 'negative'),\n",
    "('I am not looking forward to the concert', 'negative'),\n",
    "('He is my enemy', 'negative'),\n",
    "('this is not a regular delay reason  irresponsability of the crew Im just really upset  we should be compensated','negative'),\n",
    "('ticket agent refused to even check status of upgrade   gate agent said ticketing should have done it','negative'),\n",
    "('united Fifth flight on your airline in the past six weeks that has been late   you d think I d learn ', 'negative'),\n",
    "('or you can reinstate my ticket  the one you stole  and put me in a hotel room','negative'),\n",
    "('worried about the luggage being damaged underneath the plane','negative'),\n",
    "('AmericanAir terrible','negative'),\n",
    "('we only missed our flight because we were denied priority check in','negative')\n",
    "]\n",
    "\n",
    "\n",
    "neu_tweets = [('for having @djsnake #Encore album on demand', 'neutral'),\n",
    "('I\\'m 2 trips short of a list....Gotta work on that', 'neutral'),\n",
    "('just landed', 'neutral'),\n",
    "('Happy Holidays from  AmericanAir', 'neutral')\n",
    "              ('@USAirways I think it\\'s ok.', 'neutral'),\n",
    "('@JetBlue Has DC Thinking About Summer With New Nantucket Service','neutral'),\n",
    "('@united got it, look forward to hearing from you soon','neutral'),\n",
    "('@JetBlue Airways to continue various commercial relationships with #Lufthansa','neutral')\n",
    "]\n",
    "\n",
    "#########\n",
    "tweets = []\n",
    "for (words, sentiment) in pos_tweets + neg_tweets +neu_tweets:\n",
    "        words_filtered = [e.lower() for e in words.split() if len(e) >=3] \n",
    "        tweets.append((words_filtered, sentiment))\n",
    "\n",
    "#######this gets the frequency of words in postivie and negative\n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n",
    "    \n",
    "word_features = get_word_features(get_words_in_tweets(tweets))\n",
    "\n",
    "#print(word_features)\n",
    "#feature extractor returns a dictionary indicating what words\n",
    "\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "######training and classifier\n",
    "training_set = nltk.classify.apply_features(extract_features,tweets)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "\n",
    "#tweet=\"Bob is awesome\"\n",
    "\n",
    "\n",
    "#print(classifier.classify(extract_features(tweet.split())))\n",
    "\n",
    "json_data = open('airlinetweetpull_airline_Dec_06_2016.json').read()\n",
    "data = json.loads(json_data)\n",
    "\n",
    "sentiment=[]\n",
    "for l in data:\n",
    "    classificaiton = classifier.classify(extract_features(l.split()))\n",
    "    sentiment.append((l, classificaiton))\n",
    "print(sentiment)\n",
    "    \n",
    "\n",
    "keyword=\"sentiment\"\n",
    "t=time.localtime()\n",
    "timestamp = time.strftime('%b_%d_%Y',t)\n",
    "        #with open('tweet_stream_{}_{}.json'.format('Airlines', timestamp), 'w') as f:\n",
    "with open('{}_{}.json'.format(keyword, timestamp), 'w') as f:    \n",
    "    json.dump(sentiment, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code created our plane wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "d = path.dirname('/Users/shannonlamberson/Dropbox/00_public1/FinalProject/')\n",
    "\n",
    "# Read the whole text.\n",
    "text = open(path.join(d,'Plane.txt')).read()\n",
    "\n",
    "# read the mask / color image\n",
    "# taken from http://jirkavinse.deviantart.com/art/quot-Real-Life-quot-Alice-282261010\n",
    "alice_coloring = np.array(Image.open(path.join(d, \"airplane.png\")))\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add(\"said\")\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=alice_coloring,\n",
    "               stopwords=stopwords, max_font_size=60, random_state=42)\n",
    "# generate word cloud\n",
    "wc.generate(text)\n",
    "\n",
    "# create coloring from image\n",
    "image_colors = ImageColorGenerator(alice_coloring)\n",
    "\n",
    "# show\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "# recolor wordcloud and show\n",
    "# we could also give color_func=image_colors directly in the constructor\n",
    "plt.imshow(wc.recolor(color_func=image_colors))\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "plt.imshow(alice_coloring, cmap=plt.cm.gray)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The following code gives sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import operator\n",
    "import string\n",
    "import nltk\n",
    "import collections\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "\n",
    "# open a text file\n",
    "f = open('/Users/shannonlamberson/Dropbox/00_public1/FinalProject/Plane.txt')\n",
    "lines = f.read().split(',')\n",
    "f.close()\n",
    "\n",
    "p= string.punctuation\n",
    "d= string.digits\n",
    "\n",
    "table_p = string.maketrans(p, len(p) * \" \")\n",
    "table_d = string.maketrans(d, len(d) * \" \")\n",
    "\n",
    "wordsplit = []\n",
    "for ln in lines:\n",
    "    line=ln.lstrip()\n",
    "    line=line.translate(table_p)\n",
    "    line=line.translate(table_d)\n",
    "    words = line.strip().split()\n",
    "    for word in words:\n",
    "         if len(word)>6:\n",
    "             wordsplit.append(word)\n",
    "    else:\n",
    "        pass\n",
    "#print(wordsplit)\n",
    "tb=TextBlob(str(wordsplit))\n",
    "print tb.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code created the word frequency chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount={}\n",
    "#for word in file.read().split():\n",
    "for word in wordsplit:\n",
    "    if len(word)>6:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "            \n",
    "#print(wordcount)\n",
    "\n",
    "freq = nltk.FreqDist(wordcount)\n",
    "freq.plot(30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are commands that we used to create variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "These are commands that we used to create variables.\n",
    "tabulate airline, gen(airline_dummy)  # this line generated 6 numeric dummy vaiables out of the Airline string data\n",
    "\n",
    "rename airline_dummy1 American_dum\n",
    "\n",
    "rename airline_dummy2 delta_dum\n",
    "\n",
    "rename airline_dummy3 southwest_dum\n",
    "\n",
    "rename airline_dummy4 usairways_dum\n",
    "\n",
    "rename American_dum american_dum\n",
    "\n",
    "rename airline_dummy5 united_dum\n",
    "\n",
    "rename airline_dummy6 virgin_dum\n",
    "\n",
    "\n",
    "tabulate airline_sentiment, gen(sentiment_dummy) # this created 3 dummy variables from the Sentiment sting data\n",
    "\n",
    "Sentiment dummy is 3 = Positive, 2 = Neutral, 1 = Negative\n",
    "i.e. sentiment_dummy3\n",
    "Below, we used  an indicator variable to allow all sentiment to repesenten numerically in one column\n",
    "gen sent_indicator = 0\n",
    "replace sent_indicator =1 if sentiment_dummy1==1\n",
    "replace sent_indicator =2 if sentiment_dummy2==1\n",
    "replace sent_indicator =3 if sentiment_dummy3==1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
